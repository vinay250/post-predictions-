{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'e:\\\\endtoendpost'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'e:\\\\'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"MLFLOW_TRACKING_URI\"]=\"https://dagshub.com/vinayakavirat008/post-predictions-.mlflow \"\n",
    "os.environ[\"MLFLOW_TRACKING_USERNAME\"]=\"vinayakavirat008\"\n",
    "os.environ[\"MLFLOW_TRACKING_PASSWORD\"]=\"8006a8c9e77082e90d96573a13bb278110094dff\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class ModelEvaluationConfig:\n",
    "    root_dir: Path\n",
    "    test_data_path: Path\n",
    "    model_path: Path\n",
    "    all_params: dict\n",
    "    metric_file_name: Path\n",
    "    target_column: str\n",
    "    mlflow_uri: str\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from source.postpredictions import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    \n",
    "    def get_model_evaluation_config(self) -> ModelEvaluationConfig:\n",
    "        config = self.config.model_evaluation\n",
    "        params = self.params.ElasticNet\n",
    "        schema =  self.schema.TARGET_COLUMN\n",
    "\n",
    "        create_directories([config.root_dir])\n",
    "\n",
    "        model_evaluation_config = ModelEvaluationConfig(\n",
    "            root_dir=config.root_dir,\n",
    "            test_data_path=config.test_data_path,\n",
    "            model_path = config.model_path,\n",
    "            all_params=params,\n",
    "            metric_file_name = config.metric_file_name,\n",
    "            target_column = schema.name,\n",
    "            mlflow_uri=\"https://dagshub.com/vinayakavirat008/post-predictions-.mlflow\"\n",
    "        )\n",
    "\n",
    "        return model_evaluation_config\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from urllib.parse import urlparse\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from source.postpredictions.utils.utils import load_object\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelEvaluation:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def log_info(self, message):\n",
    "        mlflow.log_text(\"info\", message)\n",
    "\n",
    "    def initiate_model_evaluation(self, train_array, test_array):\n",
    "        try:\n",
    "            # Split features (X_test) and target variable (y_test) from the test_array\n",
    "            X_test, y_test = test_array[:, :-1], test_array[:, -1]\n",
    "\n",
    "            # Load the trained model\n",
    "            model_path = os.path.join(\"artifacts\", \"model.pkl\")\n",
    "            model = load_object(model_path)\n",
    "\n",
    "            # Set the MLflow registry URI\n",
    "            mlflow.set_registry_uri(\"https://dagshub.com/vinayakavirat008/post-predictions-.mlflow\")\n",
    "            \n",
    "            # Get the type of the tracking URI\n",
    "            tracking_url_type_store = urlparse(mlflow.get_tracking_uri()).scheme\n",
    "            \n",
    "            self.log_info(f\"Tracking URL Type: {tracking_url_type_store}\")\n",
    "\n",
    "            # Start a new MLflow run\n",
    "            with mlflow.start_run():\n",
    "                print(mlflow.get_tracking_uri())\n",
    "\n",
    "\n",
    "                self.log_info(\"Making predictions using the test set\")\n",
    "                predicted_qualities = model.predict(X_test)\n",
    "\n",
    "                self.log_info(\"Evaluating the model and logging classification metrics\")\n",
    "                accuracy = accuracy_score(y_test, predicted_qualities)\n",
    "                classification_rep = classification_report(y_test, predicted_qualities)\n",
    "                confusion_mat = confusion_matrix(y_test, predicted_qualities)\n",
    "\n",
    "                # Log metrics\n",
    "                mlflow.log_metric(\"accuracy\", accuracy)\n",
    "\n",
    "                # If using a remote registry, register the model in the Model Registry\n",
    "                if tracking_url_type_store != \"file\":\n",
    "                    mlflow.sklearn.log_model(model, \"model\", registered_model_name=\"ml_model\")\n",
    "                else:\n",
    "                    # If using a local file store, log the model without registering\n",
    "                    mlflow.sklearn.log_model(model, \"model\")\n",
    "\n",
    "                # Log classification metrics\n",
    "                mlflow.log_text(\"classification_report\", classification_rep)\n",
    "                mlflow.log_artifact(confusion_mat, \"confusion_matrix.txt\")\n",
    "        \n",
    "        except Exception as e:\n",
    "            self.log_info(f\"Exception occurred: {str(e)}\")\n",
    "            raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dagshub\n",
    "import mlflow\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Repository initialized!\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Repository initialized!\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dagshub.init(\"post-predictions-\", \"vinayakavirat008\", mlflow=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'source.postpredictions.model_trainer'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[59], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m accuracy_score, classification_report, confusion_matrix\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msource\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpostpredictions\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_trainer\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ModelTrainer\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Load your dataset or perform any data loading and preprocessing here\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# Example:\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m#df = pd.read_csv(\"notebooks/data/dataset1.csv\")\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# Split the data into features (X) and target variable (y)\u001b[39;00m\n\u001b[0;32m     14\u001b[0m X \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFacebook Post\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'source.postpredictions.model_trainer'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from urllib.parse import urlparse\n",
    "import mlflow\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from source.postpredictions.model_trainer import ModelTrainer\n",
    "\n",
    "\n",
    "# Load your dataset or perform any data loading and preprocessing here\n",
    "# Example:\n",
    "#df = pd.read_csv(\"notebooks/data/dataset1.csv\")\n",
    "\n",
    "# Split the data into features (X) and target variable (y)\n",
    "X = df['Facebook Post']\n",
    "y = df['Emotion']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Now you can initiate the model training\n",
    "model_trainer = ModelTrainer()\n",
    "transformed_data = model_trainer.initiate_model_training(X_train, y_train, X_test, y_test)\n",
    "\n",
    "# Assuming model_trainer returns predictions for X_test\n",
    "y_pred = model_trainer.predict(X_test)\n",
    "\n",
    "# Log metrics to MLflow\n",
    "mlflow.start_run()\n",
    "\n",
    "# Assuming you have MLflow tracking URI and credentials in environment variables\n",
    "mlflow_tracking_uri = os.environ.get(\"MLFLOW_TRACKING_URI\")\n",
    "mlflow_tracking_username = os.environ.get(\"MLFLOW_TRACKING_USERNAME\")\n",
    "mlflow_tracking_password = os.environ.get(\"MLFLOW_TRACKING_PASSWORD\")\n",
    "\n",
    "# Set the MLflow registry URI and credentials\n",
    "mlflow.set_tracking_uri(mlflow_tracking_uri)\n",
    "mlflow.set_credentials(username=mlflow_tracking_username, password=mlflow_tracking_password)\n",
    "\n",
    "# Start an MLflow run\n",
    "with mlflow.start_run():\n",
    "\n",
    "    # Log metrics to MLflow\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    classification_rep = classification_report(y_test, y_pred)\n",
    "    confusion_mat = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "    mlflow.log_metric(\"accuracy\", accuracy)\n",
    "    mlflow.log_text(\"classification_report\", classification_rep)\n",
    "    mlflow.log_artifact(confusion_mat, \"confusion_matrix.txt\")\n",
    "\n",
    "# Log additional information to DVC\n",
    "# dagshub.log(\"My DVC metrics\", metric=123, other_metric=456)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[53], line 18\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Your data loading and preprocessing code here...\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Start an MLflow run\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m mlflow\u001b[38;5;241m.\u001b[39mstart_run():\n\u001b[0;32m     11\u001b[0m \n\u001b[0;32m     12\u001b[0m     \u001b[38;5;66;03m# Your model training and evaluation code here...\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     16\u001b[0m     \n\u001b[0;32m     17\u001b[0m     \u001b[38;5;66;03m# Log metrics to MLflow\u001b[39;00m\n\u001b[1;32m---> 18\u001b[0m     accuracy \u001b[38;5;241m=\u001b[39m accuracy_score(\u001b[43my_test\u001b[49m, y_pred)\n\u001b[0;32m     19\u001b[0m     classification_rep \u001b[38;5;241m=\u001b[39m classification_report(y_test, y_pred)\n\u001b[0;32m     20\u001b[0m     confusion_mat \u001b[38;5;241m=\u001b[39m confusion_matrix(y_test, y_pred)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'y_test' is not defined"
     ]
    }
   ],
   "source": [
    "# train_and_evaluate.py\n",
    "\n",
    "import dagshub\n",
    "import mlflow\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# Your data loading and preprocessing code here...\n",
    "\n",
    "# Start an MLflow run\n",
    "with mlflow.start_run():\n",
    "\n",
    "    # Your model training and evaluation code here...\n",
    "    # For example:\n",
    "    # model.fit(X_train, y_train)\n",
    "    # y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Log metrics to MLflow\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    classification_rep = classification_report(y_test, y_pred)\n",
    "    confusion_mat = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "    mlflow.log_metric(\"accuracy\", accuracy)\n",
    "    mlflow.log_text(\"classification_report\", classification_rep)\n",
    "    mlflow.log_artifact(confusion_mat, \"confusion_matrix.txt\")\n",
    "\n",
    "# Log DVC metrics\n",
    "dagshub.log(\"My DVC metrics\", metric=123, other_metric=456)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
